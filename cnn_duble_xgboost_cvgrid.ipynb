{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of cnn_xgboost.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNeM5HAFXMPq11OgB8H/bc+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goransavich/cnn-xgboost/blob/main/cnn_duble_xgboost_cvgrid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ifLM3-XlUC8"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "#from keras.utils import np_utils\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Activation, Convolution1D, MaxPooling1D, Flatten, Input, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import shuffle\n",
        "from keras.layers.merge import concatenate\n",
        "#xgboost\n",
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "from sklearn import metrics"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjNZDZ26ljnt",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "41a929e2-e437-4071-dbd5-b769ac89c1fc"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "train_name = list(uploaded.keys())[0]\n",
        "\n",
        "train_df = pd.read_csv(io.BytesIO(uploaded[train_name]))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-078cca87-39d8-4797-984b-9017c0138cbf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-078cca87-39d8-4797-984b-9017c0138cbf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving BeetleFly_TRAIN.csv to BeetleFly_TRAIN (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI06qQRplofS",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "bf918112-e56e-48ab-b337-4a77557f316a"
      },
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "test_name = list(uploaded.keys())[0]\n",
        "\n",
        "test_df = pd.read_csv(io.BytesIO(uploaded[test_name]))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b9fdc994-468d-4a1b-bba0-69ceeb8ddb5e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b9fdc994-468d-4a1b-bba0-69ceeb8ddb5e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving BeetleFly_TEST.csv to BeetleFly_TEST (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxwm8HLKcZTk"
      },
      "source": [
        "train_data = np.array(train_df)\n",
        "test_data = np.array(test_df)\n",
        "#train_data, test_data = shuffle(train_data, test_data)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnwXjmpvcquA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e860dd2-b15d-4cb0-e577-fc3b718fb1be"
      },
      "source": [
        "x_train = train_data[:, :-1]\n",
        "x_test = test_data[:, :-1]\n",
        "train_y = train_data[:, -1:] \n",
        "test_y = test_data[:, -1:]\n",
        "\n",
        "count_train = np.unique(train_y, return_counts=True)\n",
        "count_test = np.unique(test_y, return_counts=True)\n",
        "\n",
        "print(count_train[1])\n",
        "print(count_test[1])\n",
        "\n",
        "classes_in_dataset = len(np.unique(np.concatenate((train_y, test_y), axis=0)))\n",
        "\n",
        "# transform the labels from integers to one hot vectors\n",
        "enc = OneHotEncoder(categories='auto')\n",
        "enc.fit(np.concatenate((train_y, test_y), axis=0).reshape(-1, 1))\n",
        "y_train = enc.transform(train_y.reshape(-1, 1)).toarray()\n",
        "y_test = enc.transform(test_y.reshape(-1, 1)).toarray()\n",
        "\n",
        "x_train.shape\n",
        "x_test.shape"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10 10]\n",
            "[10 10]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOzO4uOwcl0E"
      },
      "source": [
        "x_train,x_validate,y_train,y_validate = train_test_split(x_train,y_train,test_size = 0.1,random_state = 42)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8vqwl0gltg7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6986bdb9-5df9-4b61-94c4-a615b526051a"
      },
      "source": [
        "if len(x_train.shape) == 2:  # if univariate\n",
        "        # add a dimension to make it multivariate with one dimension \n",
        "        x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "        x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "print(input_shape)\n",
        "\n",
        "print('Number of classes : {}'.format(classes_in_dataset))\n",
        "###y_train for xgboost without encoding\n",
        "y_train_xgboost = enc.inverse_transform(y_train)\n",
        "\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "print(x_validate.shape)\n",
        "print(y_validate.shape)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 1)\n",
            "Number of classes : 2\n",
            "(18, 512, 1)\n",
            "(18, 2)\n",
            "(20, 512, 1)\n",
            "(20, 2)\n",
            "(2, 512)\n",
            "(2, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69xAmtJ7eCVb",
        "outputId": "35af9b8e-1623-42e1-95a6-0a41a21370eb"
      },
      "source": [
        "inputs = input_shape\n",
        "input_layer = Input(inputs)\n",
        "\n",
        "###################### first feature extractor #####################\n",
        "conv1d1 = Convolution1D(filters=6, kernel_size=7, padding='valid')(input_layer)\n",
        "activation1d1 = Activation('sigmoid')(conv1d1)\n",
        "maxpooling1d1 = MaxPooling1D(pool_size=2, strides=1, padding='valid')(activation1d1)\n",
        "#dropout1 = Dropout(0.3)(maxpooling1)\n",
        "\n",
        "conv1d2 = Convolution1D(filters=12, kernel_size=7, padding='valid')(maxpooling1d1)\n",
        "activation1d2 = Activation('sigmoid')(conv1d2)\n",
        "maxpooling1d2 = MaxPooling1D(pool_size=2, strides=1, padding='valid')(activation1d2)\n",
        "#dropout1d1 = Dropout(0.3)(maxpooling1d2)\n",
        "flatten1 = Flatten()(maxpooling1d2)\n",
        "###################### second feature extractor #####################\n",
        "\n",
        "conv2d1 = Convolution1D(filters=6, kernel_size=7, padding='valid')(input_layer)\n",
        "activation2d1 = Activation('sigmoid')(conv2d1)\n",
        "maxpooling2d1 = MaxPooling1D(pool_size=2, strides=1, padding='valid')(activation2d1)\n",
        "#dropout1 = Dropout(0.3)(maxpooling2d1)\n",
        "\n",
        "conv2d2 = Convolution1D(filters=12, kernel_size=7, padding='valid')(maxpooling2d1)\n",
        "activation2d2 = Activation('sigmoid')(conv2d2)\n",
        "maxpooling2d2 = MaxPooling1D(pool_size=2, strides=1, padding='valid')(activation2d2)\n",
        "#dropout1d2 = Dropout(0.3)(maxpooling2d2)\n",
        "flatten2 = Flatten()(maxpooling2d2)\n",
        "\n",
        "##################### concatenate ###################################\n",
        "flatten = concatenate([flatten1, flatten2])\n",
        "\n",
        "dense1 = Dense(512)(flatten) ##kernel_regularizer=l2(0.001)\n",
        "activation3 = Activation('sigmoid')(dense1)\n",
        "\n",
        "dense2 = Dense(units=classes_in_dataset)(activation3)\n",
        "activation4 = Activation('softmax')(dense2)\n",
        "\n",
        "output_for_xgboost = Model(inputs=input_layer, outputs=flatten)\n",
        "model = Model(inputs=input_layer, outputs=activation4)\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
        "\n",
        "model.compile(loss ='mean_squared_error', optimizer='Adam',metrics =['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=8,\n",
        "    epochs=400,\n",
        "    verbose=1,\n",
        "    #callbacks=[callback],\n",
        "    validation_data=(x_validate,y_validate),\n",
        ")\n",
        "\n",
        "score = model.evaluate(x_test,y_test,verbose=0)\n",
        "print('Test Loss : {:.4f}'.format(score[0]))\n",
        "print('Test Accuracy : {:.4f}'.format(score[1]))\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.4697 - accuracy: 0.3889 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 2/400\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 3/400\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 4/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 5/400\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 6/400\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 7/400\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 8/400\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 9/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 10/400\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 11/400\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 12/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 13/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 14/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 15/400\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 16/400\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 17/400\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 18/400\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 19/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 20/400\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 21/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 22/400\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 23/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 24/400\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 25/400\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 26/400\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 27/400\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 28/400\n",
            "3/3 [==============================] - 0s 78ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 29/400\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 30/400\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 31/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 32/400\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 33/400\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 34/400\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 35/400\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 36/400\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 37/400\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 38/400\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 39/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 40/400\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 41/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 42/400\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 43/400\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 44/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 45/400\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 46/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 47/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 48/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 49/400\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 50/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 51/400\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 52/400\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 53/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 54/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 55/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 56/400\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 57/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 58/400\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 59/400\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 60/400\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 61/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 62/400\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 63/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 64/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 65/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 66/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 67/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 68/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 69/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 70/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 71/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 72/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 73/400\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 74/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 75/400\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 76/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 77/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 78/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 79/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 80/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 81/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 82/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 83/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 84/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 85/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 86/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 87/400\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 88/400\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 89/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 90/400\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 91/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 92/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 93/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 94/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 95/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 96/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 97/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 98/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 99/400\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 100/400\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 101/400\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 102/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 103/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 104/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 105/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 106/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 107/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 108/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 109/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 110/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 111/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 112/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 113/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 114/400\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 115/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 116/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 117/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 118/400\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 119/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 120/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 121/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 122/400\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 123/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 124/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 125/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 126/400\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 127/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 128/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 129/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 130/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 131/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 132/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 133/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 134/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 135/400\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 136/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 137/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 138/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 139/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 140/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 141/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 142/400\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 143/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 144/400\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 145/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 146/400\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 147/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 148/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 149/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 150/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 151/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 152/400\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 153/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 154/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 155/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 156/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 157/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 158/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 159/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 160/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 161/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 162/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 163/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 164/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 165/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 166/400\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 167/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 168/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 169/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 170/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 171/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 172/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 173/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 174/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 175/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 176/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 177/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 178/400\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 179/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 180/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 181/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 182/400\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 183/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 184/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 185/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 186/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 187/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 188/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 189/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 190/400\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 191/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 192/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 193/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 194/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 195/400\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 196/400\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 197/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 198/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 199/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 200/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 201/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 202/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 203/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 204/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 205/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 206/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 207/400\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 208/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 209/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 210/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 211/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 212/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 213/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 214/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 215/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 216/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 217/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 218/400\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 219/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 220/400\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 221/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 222/400\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 223/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 224/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 225/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 226/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 227/400\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 228/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 229/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 230/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 231/400\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 232/400\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 233/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 234/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 235/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 236/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 237/400\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 238/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 239/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 240/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 241/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 242/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 243/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 244/400\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 245/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 246/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 247/400\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 248/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 249/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 250/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 251/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 252/400\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 253/400\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 254/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 255/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 256/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 257/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 258/400\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 259/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 260/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 261/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 262/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 263/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 264/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 265/400\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 266/400\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 267/400\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 268/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 269/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 270/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 271/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 272/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 273/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 274/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 275/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 276/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 277/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 278/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 279/400\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 280/400\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 281/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 282/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 283/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 284/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 285/400\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 286/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 287/400\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 288/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 289/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 290/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 291/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 292/400\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 293/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 294/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 295/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 296/400\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 297/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 298/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 299/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 300/400\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 301/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 302/400\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 303/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 304/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 305/400\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 306/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 307/400\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 308/400\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 309/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 310/400\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 311/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 312/400\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 313/400\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 314/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 315/400\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 316/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 317/400\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 318/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 319/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 320/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 321/400\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 322/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 323/400\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 324/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 325/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 326/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 327/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 328/400\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 329/400\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 330/400\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 331/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 332/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 333/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 334/400\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 335/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 336/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 337/400\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 338/400\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 339/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 340/400\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 341/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 342/400\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 343/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 344/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 345/400\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 346/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 347/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 348/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 349/400\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 350/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 351/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 352/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 353/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 354/400\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 355/400\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 356/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 357/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 358/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 359/400\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 360/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 361/400\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 362/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 363/400\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 364/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 365/400\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 366/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 367/400\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 368/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 369/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 370/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 371/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 372/400\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 373/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 374/400\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 375/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 376/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 377/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 378/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 379/400\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 380/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 381/400\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 382/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 383/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 384/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 385/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 386/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 387/400\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 388/400\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 389/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 390/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 391/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 392/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 393/400\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 394/400\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 395/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 396/400\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 397/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 398/400\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 399/400\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Epoch 400/400\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.5000 - accuracy: 0.5000 - val_loss: 0.5000 - val_accuracy: 0.5000\n",
            "Test Loss : 0.5000\n",
            "Test Accuracy : 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "Kg2jWIz_TtlX",
        "outputId": "e1d6116a-6fcb-495a-eafe-d6bf83ebc1cb"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Training - Loss Function')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Train - Accuracy')"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Train - Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0MA-9s3RrWT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3c15ae6-5dcf-424f-e691-7136b8de27fa"
      },
      "source": [
        "######### XGBOOST #############\n",
        "\n",
        "intermediate_layer_model = output_for_xgboost\n",
        "\n",
        "intermediate_layer_model.summary()\n",
        "\n",
        "x_train_xgboost = intermediate_layer_model.predict(x_train)\n",
        "x_test_xgboost = intermediate_layer_model.predict(x_test)\n",
        "\n",
        "#label encoder for y to be in range from 0 to num-classes\n",
        "def transform_labels(y_train_xgboost, test_y):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    y_t_xgboost = le.fit_transform(y_train_xgboost)\n",
        "    t_y = le.fit_transform(test_y)\n",
        "    return y_t_xgboost, t_y\n",
        "\n",
        "y_tr_xgboost, test_y_xgboost = transform_labels(y_train_xgboost, test_y)\n",
        "\n",
        "xgboost_train_dataset = np.concatenate([np.array(x_train_xgboost).reshape(x_train.shape[0],flatten.shape[1]),np.array(y_tr_xgboost).reshape(y_tr_xgboost.shape[0],1)],axis=1)\n",
        "xgboost_train_dataset = pd.DataFrame(xgboost_train_dataset)\n",
        "xgboost_train_dataset.to_csv('train_xgboost.csv',index=False)\n",
        "\n",
        "xgboost_test_dataset = np.concatenate([np.array(x_test_xgboost).reshape(x_test.shape[0],flatten.shape[1]),np.array(test_y_xgboost).reshape(test_y_xgboost.shape[0],1)],axis=1)\n",
        "xgboost_test_dataset = pd.DataFrame(xgboost_test_dataset)\n",
        "xgboost_test_dataset.to_csv('test_xgboost.csv',index=False)\n",
        "\n",
        "train_column = str(flatten.shape[1])\n",
        "\n",
        "train = pd.read_csv('train_xgboost.csv')\n",
        "train_y = train[train_column].astype('int')\n",
        "train_x = train.drop([train_column],axis=1)\n",
        "\n",
        "test = pd.read_csv('test_xgboost.csv')\n",
        "test_y = test[train_column].astype('int')\n",
        "test_x = test.drop([train_column],axis=1)\n",
        "\n",
        "print(train_y.shape)\n",
        "print(test_y.shape)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "parameters_grid=[{'eta':[0.1,0.2,0.3,0.4],\n",
        "                  'max_depth':[3,4,5,6,7,8],\n",
        "                  'lambda':[0,1,10]}]\n",
        "\n",
        "estimator = XGBClassifier(\n",
        "    nthread=4,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=estimator,\n",
        "    param_grid=parameters_grid,\n",
        "    scoring = 'accuracy',\n",
        "    n_jobs = 10,\n",
        "    cv = 4,\n",
        "    verbose=True\n",
        ")\n",
        "     \n",
        "train_x = train_x.to_numpy()\n",
        "train_y = train_y.to_numpy()\n",
        "test_x = test_x.to_numpy()\n",
        "test_y = test_y.to_numpy()\n",
        "#watchlist = [(dataset, 'train')]\n",
        "#params = {'max_depth':5, 'eta':0.3, 'silent':1,  'num_class': classes_in_dataset} \n",
        "model_xg = grid_search.fit(train_x, train_y)\n",
        "\n",
        "model_xg.best_params_\n",
        "print(model_xg.best_params_)\n",
        "#test_x = xgb.DMatrix(test_x)\n",
        "result = model_xg.predict(test_x)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            [(None, 512, 1)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_24 (Conv1D)              (None, 506, 6)       48          input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_26 (Conv1D)              (None, 506, 6)       48          input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 506, 6)       0           conv1d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 506, 6)       0           conv1d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_24 (MaxPooling1D) (None, 505, 6)       0           activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_26 (MaxPooling1D) (None, 505, 6)       0           activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_25 (Conv1D)              (None, 499, 12)      516         max_pooling1d_24[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_27 (Conv1D)              (None, 499, 12)      516         max_pooling1d_26[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 499, 12)      0           conv1d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 499, 12)      0           conv1d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_25 (MaxPooling1D) (None, 498, 12)      0           activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_27 (MaxPooling1D) (None, 498, 12)      0           activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_12 (Flatten)            (None, 5976)         0           max_pooling1d_25[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_13 (Flatten)            (None, 5976)         0           max_pooling1d_27[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 11952)        0           flatten_12[0][0]                 \n",
            "                                                                 flatten_13[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,128\n",
            "Trainable params: 1,128\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f94a2191320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18,)\n",
            "(20,)\n",
            "Fitting 4 folds for each of 72 candidates, totalling 288 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:   21.8s\n",
            "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=10)]: Done 288 out of 288 | elapsed:  3.0min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eta': 0.1, 'lambda': 0, 'max_depth': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT6wPCUXVqqA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aade8a26-8d7e-41c7-bbd7-9d955d5638c2"
      },
      "source": [
        "\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "#preds = model.predict(d_test)\n",
        "#best_preds = np.asarray([np.argmax(line) for line in result])\n",
        "\n",
        "print(\"Precision = {}\".format(precision_score(test_y, result, average='macro', zero_division=0)))\n",
        "print(\"Recall = {}\".format(recall_score(test_y, result, average='macro', zero_division=0)))\n",
        "print(\"Accuracy = {}\".format(accuracy_score(test_y, result)))\n",
        "print(\"F1 score = {}\".format(f1_score(test_y, result, average='macro', zero_division=0)))\n",
        "\n",
        "print(metrics.classification_report(test_y, result))\n",
        "print(metrics.confusion_matrix(test_y, result))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision = 0.7747252747252746\n",
            "Recall = 0.75\n",
            "Accuracy = 0.75\n",
            "F1 score = 0.7442455242966751\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.90      0.78        10\n",
            "           1       0.86      0.60      0.71        10\n",
            "\n",
            "    accuracy                           0.75        20\n",
            "   macro avg       0.77      0.75      0.74        20\n",
            "weighted avg       0.77      0.75      0.74        20\n",
            "\n",
            "[[9 1]\n",
            " [4 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQepJPHZe0pX"
      },
      "source": [
        ""
      ],
      "execution_count": 83,
      "outputs": []
    }
  ]
}